\documentclass[11pt,a4paper,openany, twosided]{book}
\makeatletter
\title{MEMOIRE}
\makeatletter
\newcommand{\crossout}[1]{%
\begingroup
\settowidth{\dimen@}{#1}%
\setlength{\unitlength}{0.05\dimen@}%
\settoheight{\dimen@}{#1}%
\count@=\dimen@
\divide\count@ by \unitlength
\count0=20 \count4=\count@\\
\loop
\count2=\count0 % keep a copy
\divide\count2\count4 \multiply\count2\count4
\ifnum\count2<\count0
\advance\count0 -\count2 % the remainder
\count2=\count0
\count0=\count4
\count4=\count2
\repeat
\count0=20 \divide\count0\count4
\count2=\count@ \divide\count2\count4
\begin{picture}(0,0)
\put(0,0){\line(\count0,\count2){20}}
\put(0,\count@){\line(\count0,-\count2){20}}
\end{picture}%
#1%
\endgroup
}
\makeatother
\newcommand\independent{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}

\makeatletter % No page counter for \part
\renewcommand\part{%
	\if@openright
	\cleardoublepage
	\else
	\clearpage
	\fi
	\thispagestyle{empty}%   % Original »plain« replaced by »emptyx
	\if@twocolumn
	\onecolumn
	\@tempswatrue
	\else
	\@tempswafalse
	\fi
	\null\vfil
	\secdef\@part\@spart}
\makeatother

\usepackage{scalerel,stackengine}
\stackMath
\newcommand\reallywidehat[1]{%
	\savestack{\tmpbox}{\stretchto{%
			\scaleto{%
				\scalerel*[\widthof{\ensuremath{#1}}]{\kern-.6pt\bigwedge\kern-.6pt}%
				{\rule[-\textheight/2]{1ex}{\textheight}}%WIDTH-LIMITED BIG WEDGE
			}{\textheight}% 
		}{0.5ex}}%
	\stackon[1pt]{#1}{\tmpbox}%
}


\usepackage{newclude} % delete \newpage with \include*{}
\usepackage{booktabs,multirow}% 

\usepackage[dvipsnames]{xcolor}
\usepackage[utf8]{inputenc} 
\usepackage[T1]{fontenc} 
%\usepackage[sc]{
\usepackage{lmodern}
%\usepackage[nomath]{kpfonts} % coment to return to lpmodern complet
\usepackage{libertine}%  serif and sans 
%\usepackage[scaled=0.85]{beramono}%% mono
\usepackage{setspace}
\linespread{1.05}

\usepackage[english]{babel}
\usepackage[a4paper]{geometry}
\usepackage{graphicx}
\usepackage[font=small,labelfont={bf,it},textfont=it]{caption}
\usepackage{csquotes}
\usepackage{subcaption}
\usepackage{pdfpages}
\usepackage[flushleft]{threeparttable}
\usepackage{multirow}
\usepackage{footnote}
\makesavenoteenv{array}
\usepackage[bottom]{footmisc}
\usepackage{tabularx, booktabs}
\newcolumntype{Y}{>{\centering\arraybackslash}X}
\usepackage{listings}
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\usepackage{longtable}

\usepackage{sidecap}
\usepackage{pdflscape}
\usepackage{wrapfig}
\usepackage{listings}
\usepackage{babel,blindtext}
\usepackage{lipsum}
%\usepackage{slashbox}
\usepackage{dashrule}
\usepackage{hhline}
\usepackage{color}
%\usepackage{subfig}
\usepackage{graphicx}


\usepackage{amsmath} % Les math
\makeatletter
\let\reftagform@=\tagform@
\def\tagform@#1{\maketag@@@{(\ignorespaces\textcolor{blue}{#1}\unskip\@@italiccorr)}}
\renewcommand{\eqref}[1]{\textup{\reftagform@{\ref{#1}}}}
\makeatother
\usepackage{amssymb} % Symboles math
\usepackage{esvect} % Vecteurs
\usepackage[amssymb]{SIunits}
\usepackage{eurosym}
\usepackage{mathrsfs}
\usepackage{dcolumn}
\usepackage{pifont}
\usepackage{amsthm}

\usepackage[breaklinks,colorlinks]{hyperref}
\hypersetup{
colorlinks=true,linkcolor=blue,%citecolor=CornflowerBlue,naturalnames=true,hypertexnames=false,
	filecolor=magenta,      
	urlcolor=cyan,
	citecolor=ForestGreen,
}


\usepackage{etoolbox}


\usepackage[ruled,vlined]{algorithm2e}
\usepackage{mathtools}

\newcommand{\expect}{\operatorname{E}\expectarg}
\DeclarePairedDelimiterX{\expectarg}[1]{[}{]}{%
	\ifnum\currentgrouptype=16 \else\begingroup\fi
	\activatebar#1
	\ifnum\currentgrouptype=16 \else\endgroup\fi
}
\newcommand{\innermid}{\nonscript\;\delimsize\vert\nonscript\;}
\newcommand{\activatebar}{%
	\begingroup\lccode`\~=`\|
	\lowercase{\endgroup\let~}\innermid 
	\mathcode`|=\string"8000
}
\newlength{\mylen}  % change size of items
\setbox1=\hbox{$\bullet$}\setbox5=\hbox{\normalsize$\bullet$}
\setlength{\mylen}{\dimexpr0.5\ht1-0.5\ht2}
\makeatletter
% Patch case where name and year are separated by aysep
\patchcmd{\NAT@cite}
{\@cite\NAT@hyper@{%
		\NAT@nmfmt{\NAT@nm}%
		\hyper@natlinkbreak{\NAT@aysep\NAT@spacechar}{\@citeb\@extra@b@citeb}%
		\NAT@date}}
{\@cite\NAT@nmfmt{\NAT@nm}%
	\NAT@aysep\NAT@spacechar\NAT@hyper@{\NAT@date}}{}{}

% Patch case where name and year are separated by opening bracket
\patchcmd{\NAT@cite}
{\@cite\NAT@hyper@{%
		\NAT@nmfmt{\NAT@nm}%
		\hyper@natlinkbreak{\NAT@spacechar\NAT@@open\if#1\else#1\NAT@spacechar\fi}%
		{\@citeb\@extra@b@citeb}%
		\NAT@date}}
{\@cite\NAT@nmfmt{\NAT@nm}%
	\NAT@spacechar\NAT@@open\if#1\else#1\NAT@spacechar\fi\NAT@hyper@{\NAT@date}}
{}{}

\makeatother

\usepackage{datetime} 
\usepackage{bm}
\usepackage{scalerel,stackengine}
\usepackage{pbox}
\usepackage{vmargin}            
\setmarginsrb{2,5cm}{2,7cm}{2,5cm}{2,5cm}{0cm}{1cm}{0cm}{1cm}
\rmfamily
%\DeclareFontShape{T1}{lmr}{b}{sc}{<->ssub*cmr/bx/sc}{}
%\DeclareFontShape{T1}{lmr}{bx}{sc}{<->ssub*cmr/bx/sc}{}

\DeclareMathOperator*{\argminA}{arg\,max} % Jan Hlavacek
\DeclareMathOperator*{\argminB}{argmax}   % Jan Hlavacek
\DeclareMathOperator*{\argminC}{\arg\max}   % rbp

\newcommand{\argmaxD}{\arg\!\max} % AlfC

\newcommand{\argminE}{\mathop{\mathrm{argmin}}}          % ASdeL
\newcommand{\argminF}{\mathop{\mathrm{argmin}}\limits} 

\usepackage{fancyhdr}
\usepackage{afterpage}

\fancypagestyle{plain}{\fancyhf{}}
\pagestyle{fancy}
\fancyfoot{}
\cfoot{\thepage}
\fancyhead[RO,LE]{\thepage}
\fancyhead[LO]{\leftmark}
\fancyhead[RE]{\rightmark}
\renewcommand{\headrulewidth}{.6pt}

\iffalse
\copypagestyle{memoirStylePages}{headings}
\makerunningwidth{memoirStylePages}{\textwidth}
\makeheadrule{memoirStylePages}{\textwidth}{\normalrulethickness}
\pagestyle{memoirStylePages}
\fi


\pagenumbering{roman}
\newcommand{\bib}{\par\noindent\hangindent=0.5 true cm \hangafter=1}

\makeatletter  % rm pg number in bottom
\let\@oddfoot\@empty
\let\@evenfoot\@empty
\makeatother
\usepackage{appendix}
%\usepackage[style=apa,backref=true,backend=biber,natbib=true,hyperref=true]{biblatex} 
\let\origappendix\appendix % save the existing appendix command
\renewcommand\appendix{\clearpage\pagenumbering{Roman}\origappendix}


%\addbibresource{zotero.bib.bib}
\usepackage[sort, square, comma]{natbib}
%\usepackage{natbib}
\bibliographystyle{abbrvnat}
\setcitestyle{authoryear, open = {[}, close={]} }

%\setcitestyle{square}
%\setcitestyle{authoryear, open={[},close={)]}}
%\usepackage{apacite}
%\usepackage{cite}
%\usepackage[backend=biber]{biblatex}
\usepackage{bbm}
\usepackage{enumitem}
\usepackage{minitoc}

\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
%\theoremstyle{definition}
\newtheorem{definition}{Definition}[chapter]
%\renewcommand*{\proofname}{\boxed{Proof}}
\usepackage{thmtools}

\newcommand*{\QEDB}{\hfill\ensuremath{\triangle}}%
\newcommand*{\QEDA}{\hfill\ensuremath{\blacksquare}}%

\AtEndEnvironment{theorem}{\null\hfill\qedsymbol}%
\AtEndEnvironment{definition}{\null\hfill\QEDB}%
%\declaretheorem[style=definition,qed=$\triangle$,sibling=definition]{definition}
%\declaretheorem[style=definition,qed=$\triangle$,sibling=definition]{theorem}
\newtheorem{exe}{Theorem}
\setcounter{exe}{-1}


\usepackage{mathtools}
\DeclarePairedDelimiter\abs{\lvert}{\rvert}
\DeclarePairedDelimiter\norm{\lVert}{\rVert}

\usepackage{multirow,bigdelim}
\usepackage{tcolorbox}
\usepackage{adjustbox}
\usepackage{dashbox}
\usepackage{todonotes}

\newcommand{\abbrlabel}[1]{\makebox[3cm][l]{\textbf{#1}\ \dotfill}}
\newenvironment{abbreviations}{\begin{list}{}{\renewcommand{\makelabel}{\abbrlabel}}}{\end{list}}


\usepackage{tikz}
\usetikzlibrary{matrix,chains,positioning,decorations.pathreplacing,arrows}
%\defbeamertemplate{itemize item}{tikzarrow}{\tikz{\node[single
%		arrow,scale=0.2,inner sep=2ex,fill] at (0,0) {};}}

\tikzset{myarrow/.style={
		draw,
		fill=Emerald,
		single arrow,
		minimum height=5.5ex,
		single arrow head extend=1ex
	}
}
\newcommand{\arrowright}{%
	\tikz [baseline=-1ex]{\node [myarrow,rotate=0] {};}
}
\setlength{\parskip}{.2em}

\usepackage{afterpage}

\newcommand\blankpage{%
    \null
    \thispagestyle{empty}%
    \addtocounter{page}{-1}%
    \newpage}


\setcounter{tocdepth}{3}
\setcounter{secnumdepth}{4}
\setcounter{minitocdepth}{4}

% Chapter head 
\makeatletter
\def\thickhrulefill{\leavevmode \leaders \hrule height 1ex \hfill \kern \z@}
\def\@makechapterhead#1{%
  {\parindent \z@ \raggedright
    \reset@font
    \hrule
    \vspace*{10\p@}%
    \par
    \Large \scshape \@chapapp{} \Huge\bfseries \thechapter
    \par\nobreak
    \vspace*{10\p@}%
    \hrule
    \par
    \vspace*{1\p@}%
    \hrule
    %\vskip 40\p@
    \vspace*{20\p@}
    \Huge \bfseries #1\par\nobreak
    \vskip 70\p@
  }}

\begin{document}
\thispagestyle{empty}


\begin{center}
	{\LARGE    UNIVERSITE CATHOLIQUE DE LOUVAIN} \\
	\vspace{0.2cm}
	{\large FACULTE DES SCIENCES} \\
	\vspace{0.2cm}
	{\Large ECOLE DE STATISTIQUE, BIOSTATISTIQUE \\
		\vspace{0.1cm}
		ET SCIENCES ACTUARIELLES }\\
\end{center}
\vfill

%\begin{figure}[H]
\begin{center}  \hspace*{-10mm} 
	\includegraphics[height = 3.5cm]{lsba.jpg}
\end{center}
%\end{figure}

\thispagestyle{empty}

\vfill


\begin{center}
	{\Large \textsc{Temporal Analysis of the Evolution of Extreme Values Using Climatological Data}}
	
\end{center}


\vfill

\begin{center}[]
	\begin{minipage}[c]{.45\linewidth}
		\begin{tabular}{ll}
			\vspace{0.2cm}
			Promoteur : & Johan \textsc{Segers} \\
			\vspace{0.2cm}
			Lecteurs : & Anna \textsc{Kiriliouk}\\
			\vspace{0.2cm}
			& Michel \textsc{Crucifix}
		\end{tabular}
	\end{minipage} \hfill
	\begin{minipage}[c]{.45\linewidth}
		\begin{tabularx}{\linewidth}{p{\textwidth}}
			Mémoire présenté en vue de \hbox{l'obtention} du \\   \vspace{0.1cm} Master en statistiques, orientation générale \\   \vspace{0.1cm} par :
			\textbf{Antoine \textsc{Pissoort}}
		\end{tabularx}
	\end{minipage}
\end{center}

\vspace{1,5cm}



\begin{center}
	{\large Aout 2017}
\end{center}
\thispagestyle{empty}
\newpage


%\centering
\topskip0pt
\vspace*{\fill}
%\addcontentsline{toc}{chapter}{Abstract}%
\section*{\centering Abstract}
\begin{tcolorbox}%[colback=SeaGreen!75!white]
This thesis provides an in-depth nonstationary analysis of recent official records of annual maximum temperatures in order to statistically evaluate global warming. Relying on various modeling techniques based upon the Extreme Value Theory, this thesis demonstrates that a nonstationary extreme value Weibull model with a linear model on the location parameter is the preferred model to explain data within a vast number of parametric and nonparametric models. This thesis proves that the scale is not significantly affected. Whilst this lead  to consideration that global warming is linear in the location of the annual maximum temperatures, other modeling techniques using splines's derivatives in a generalized additive model have previously shown that the trend on the annual maxima are not simultaneously significant over time.
While developing theoretical backgrounds on these state-of-the-art methods, this thesis carefully presents the application of these methods that are gathered into a repository and R package, enabling efficient automated analysis for the future.

\thispagestyle{empty}
\end{tcolorbox}

\vspace{.3cm}

\paragraph*{Keywords} $\bullet$ Extreme Value Theory   $\bullet$ Generalized Extreme Value  $\bullet$ Generalized Pareto Distribution $\bullet$ Nonstationary analysis $\bullet$ Bayesian inference   $\bullet$ Generalized Additive Models $\bullet$ Splines smoothing  $\bullet$ Conditional Density Networks $\bullet$ Bootstrapping methods $\bullet$ Parallel computing $\bullet$ R package $\bullet$ Shiny applications
\vspace*{\fill}

\newpage


%\afterpage{\cfoot{\thepage}}


\newenvironment{acknowledgements}%
{\thispagestyle{empty}\null\vfill\begin{center}%
\bfseries Acknowledgements\end{center}}%
{\vfill\null}
%\addcontentsline{toc}{chapter}{Acknowledgements}%
\begin{acknowledgements}
	\textit{I would first like to thank my thesis supervisor Johan Segers for all his help and his guidance during this whole year. These repeated appointments have made this thesis very interesting. }
	\newline
	
	\textit{I also would like to thank the "Institut Royal de Météorologie" (IRM) of Belgium for his help and his guidance, but also for his provided quality datasets.}
	\newline
	
	\textit{A bit less usual, but I would like to thank the open source community such as R or LaTeX can benefit. For me and for a great number of students, it has been a non-negligible source of ideas and an effective practical source of learning.  }
	\newline
	
	\textit{Also quite less usual, but I would like to thank in particular this thesis that permits me to acquire a vast knowledge on various subjects and to develop expertises in the R language. %$25$ credits that are undoubtedly worth the hundred other for this master. 
		}
   	\newline
   	
	\textit{Finally, I want to thank my family and my friends, but also Bernadette and Michel for their support and all the time I have spent  writing in their house for my thesis, but also during my whole academic studies.}
	
	\thispagestyle{empty}
\end{acknowledgements}


\afterpage{\blankpage}


\thispagestyle{empty}
\dominitoc
\thispagestyle{empty}
\tableofcontents
\thispagestyle{empty}
\newpage
\thispagestyle{empty}
\listoffigures
\thispagestyle{empty}
\listoftables
\thispagestyle{empty}

\newpage


\chapter*{List of Abbreviations}
%\addcontentsline{toc}{chapter}{List of Abbreviations}
\thispagestyle{empty}
For convenience, we place a list of all the abbreviations we will use in the text. However, these will always be defined in their first occurrence in the text.\\

\begin{center}
\begin{abbreviations}
	\item[BMA] Bayesian Model Averaging
	\item[DA] Domain of Attraction
	\item[df]\label{df}  (cumulative) distribution function
	\item[EVI] Extreme Value Index ($\xi$)
	\item[EVT] Extreme Value Theory
	\item[GEV] Generalized Extreme Value
	\item[GML] Generalized Maximum Likelihood
	\item[GPD] Generalized Pareto Distribution %(function)
	\item[MC(MC)] Marko Chain (Monte Carlo)
	\item[MH] Metropolis-Hastings 
	\item[ML] Maximum Likelihood 
	\item[MLE] Maximum Likelihood Estimator
	\item[NN] Neural Network
	\item[PP(D)] Posterior Predictive (Distribution)
	\item[TN] Temperature miNimum
	\item[TX] Temperature maXimum
	
\end{abbreviations}
\end{center}


\renewcommand\labelitemi{\normalsize$\bullet$}



\afterpage{\blankpage}


\addcontentsline{toc}{chapter}{Introduction}
\chapter*{Introduction}
	%Presentation of the Analysis }
\pagenumbering{arabic}
\thispagestyle{empty}


Extreme Value Theory (EVT) is concerned with the statistical characterization of \emph{extreme} events. 
This thesis aims at applying the EVT on broad environmental data, in particular with a meteorological application. EVT could also be applied to other areas such as risk analysis, finance or insurance. Although these are relevant on people's lives, in terms of the number of persons impacted and lives lost.
Moreover, the increase in weather extremes over the past decade has raised awareness of the importance of this subject.

There have been a number of major drought events recorded in the past few years in Ethiopia, Australia, United Stated, Eurasia, etc.  Pakistan, for example, experienced the worst flooding in $80$ years resulting in over two thousand casualties and twenty million people affected. The $2003$ European heat-wave killed approximately seventy thousand people, more than ten times the number of killed people in the September 11 attacks. 


Hence, the need for EVT to analyze these extreme events is compelling.
The data are provided by an official intitude, the "Institut Royal of Météorologie" (IRM) of Uccle. 
As the problem facing climate change evidence is often the lack of reliable past data to compare with, this thesis is based upon a homogeneous dataset with annual temperatures from $1901$ to $2016$. 


Following \citet{kharin_changes_2007}, this thesis anticipated that climate change affects extreme weather. Aware of the existence of the temporal increase of the annual maxima but having no prior idea on the form of this evolution, the research problem of this thesis can be summarized as : 
\vspace{0.1cm}
\begin{tcolorbox}%[colback=SeaGreen!75!white]
	To statistically evaluate the nonstationarity of the sequence of annual maxima in order to assess climate warming and predict the extreme events associated with this climate warming. 
\end{tcolorbox}
To this end, we can model these \emph{extremes} using two different approaches : 

\begin{itemize}
	\item as maximum observations that occur inside nonoverlapping \emph{blocks} of equal size.
	In \hyperref[sec::1]{Chapter \textbf{1}}, this thesis presents the method of \emph{block-maxima} and derive the Generalized Extreme Value (GEV) distribution; or-
	\item as observations that \emph{exceed} a certain high \emph{threshold}. This method, presented in  \hyperref[sec::2]{Chapter \textbf{2}}, is often regarded as more efficient as it can use more observations. It is called the \emph{peaks-over-threshold} approach, from which is derived the Generalized Pareto Distribution.
\end{itemize}
Since this thesis deals with an annual sequence, i.e.  maxima over a block of 1 year, the first approach will be given more attention.
While the first chapters restrict the analysis to independent sequences, in \hyperref[sec::3]{Chapter \textbf{3}} the thesis will consider dependent sequences and present tools to model nonstationary sequences.
To go beyond the somewhat restrictive parametric inferential methods in EVT, \hyperref[sec::3]{Chapter \textbf{3}}  will also consider a novel flexible model relying on a Neural Networks framework, in order to assess the nonstationarity with a significantly higher number of possible models with a state-of-the-art method. 
\hyperref[sec::bayesian]{Chapter \textbf{\ref{sec::bayesian}}} will present the Bayesian methods that can be applied for this purpose, and to take the estimation and predictive uncertainty into account.

The second part will apply these methods on the annual maxima in Uccle. \hyperref[chap:introana]{Chapter \textbf{\ref{chap:introana}}} will start with an in-depth introductory trend analysis on the maxima  in order to strictly evaluate their evolution over time, both with pointwise and simultaneous confidence intervals. 
\hyperref[sec:anagev]{Chapter \textbf{\ref{sec:anagev}}} will present the application of the EVT with the block-maxima approach with a strong emphasis on methods to make a nonstationary GEV analysis.
\hyperref[sec:anabayes]{Chapter \textbf{\ref{sec:anabayes}}} will conclude the analysis using Bayesian methods, and using newly implemented methods to introduce flexibility to the model.
\thispagestyle{empty}



\begin{center}
\part{Theoretical Framework : Extreme Value Theory}\label{part1}
\end{center}
%\pagestyle{fancy}


\setcounter{mtc}{1}
\chapter{Method of Block Maxima} \label{sec::1}
\vspace{-1cm}
\minitoc \thispagestyle{empty}
 \vspace{1cm}

This chapter introduce the basics of EVT by considering the \textit{block-maxima} approach. This approach aims at modeling the extremes inside a predefined block. 
After defining useful concepts in 
\hyperref[sec::1.1]{Section \textbf{1.1}} to introduce the emergence of this theory, we will get into the leading theorem of EVT in \hyperref[sec:extrtypethm]{Section \textbf{\ref{sec:extrtypethm}}}. \hyperref[sec::appconcrete]{Section \textbf{\ref{sec::appconcrete}}} will present some mathematical applications and \hyperref[sec:mda]{Section \textbf{\ref{sec:mda}}} conditions  of this theorem in order to visualize the implications of the extremal theorem and the characterizations of the underlying distributions. \hyperref[rlgev]{Section \textbf{\ref{rlgev}}} will introduce key concepts of inference in EVT which will be presented in a general (and frequentist) way in  \hyperref[sec::gevinfernce]{Section \textbf{\ref{sec::gevinfernce}}}. Finally, \hyperref[sec:diag]{Section \textbf{\ref{sec:diag}}} provides some tools to assess the accuracy of the fitted model.

This chapter is mostly based on \citet[chap.3]{coles_introduction_2001}, \citet[chap.2]{beirlant_statistics_2006} and \citet[chap.1-4]{reiss_statistical_2007}, and other relevant articles.

\newpage
\include*{chap1}



\chapter{Peaks-Over-Threshold Method}\label{sec::2}
\vspace{-1cm}
\minitoc \thispagestyle{empty}
 \vspace{1cm}

This chapter will focus on a major approach of EV models by modeling only the excess over a certain threshold. This approach is very popular in practice as it can handle all the extremes with more flexibility and not only the maximum of one block. From this, numerous techniques have emerged and we will navigate the main ideas.

In \hyperref[sec::2.1]{Section \textbf{\ref{sec::2.1}}}, we will introduce the approach that will help us 
to formally characterize the resulting distribution of interest in \hyperref[sec:charac_gpd]{Section \textbf{\ref{sec:charac_gpd}}}. \hyperref[sec:rl_gpd]{Section \textbf{\ref{sec:rl_gpd}}} will present the concept of return levels applied to this concept. We will then assess the maximum temperature threshold in a statistical sense in \hyperref[sec:thresh_selec]{Section \textbf{\ref{sec:thresh_selec}}} by reviewing available methods, with common suggested thresholds of $25^{\circ} c$ or $30^{\circ} c$ from meteorologists.

Unfortunately, the resulting analysis of this chapter will not be presented in \hyperref[part:xp]{Part \textbf{\ref{part:xp}}} because it would have made the text too voluminous. Empirical results (code and html reports) will remain available in the \href{https://github.com/proto4426/PissoortThesis/}{repository}\footnote{\url{https://github.com/proto4426/PissoortThesis/}}(see \hyperref[appgit]{Appendix \textbf{\ref{appgit}}}). Moreover, \emph{point process} will not be covered for the same reason but we remind that this is a powerful and flexible method that summarizes the two techniques considered in the two first chapters, and it should then not be missed. 

This chapter is mostly based on \citet[chap.4 and 7]{coles_introduction_2001}, \citet[chap.4]{beirlant_statistics_2006}, \citet[chap.5]{reiss_statistical_2007} and 
\citet[chap.5]{embrechts_modelling_2011},
 and other relevant articles.

\newpage
\include*{chap2}



\chapter{Relaxing The Independence Assumption}\label{sec::3}
\vspace{-1cm}
\minitoc\thispagestyle{empty}
 \vspace{1cm}
 
In most environmental applications, the independence assumption made in the first chapters is questionable and never completely fulfilled. From hydrological processes as stated in \citet{milly_climate_2008} to temperature data to demonstrate climate warming, such theoretical assumptions that have been previously made are not sustainable in practice. \hyperref[sec:statio]{Section \textbf{\ref{sec:statio}}} will provide tools that enable EV models to hold in presence of a limited long-range dependence.
\hyperref[nstatio]{Section \textbf{\ref{nstatio}}} will allow EV modeling under nonstationary processes that will enable us to study the possible increasing behavior of the maximum temperatures. \hyperref[sec:returnlvlnstatio]{Section \textbf{\ref{sec:returnlvlnstatio}}} will redefine return levels under those less restricted cases, and finally  \hyperref[sec:gevcdn]{Section \textbf{\ref{sec:gevcdn}}} will introduce a new flexible way to model nonstationary extremes under a redefined Multi Layer Perceptron framework with inferential techniques minimizing the risk of overfitting.


This chapter is mostly based on \citet[chap.5-6]{coles_introduction_2001}, \citet[chap.10]{beirlant_statistics_2006} and \citet[chap.7]{reiss_statistical_2007}, and other relevant articles.
\newpage
\include*{chap3}




\chapter{Bayesian Extreme Value Theory}\label{sec::bayesian}
\vspace{-1.5cm}
\minitoc\thispagestyle{empty}
 \vspace{0.1cm}


Whilst sometimes criticized for the introduction of some subjectivity, the Bayesian paradigm is increasingly adopted by practitioners for its benefits. In this case, Bayesian inference is interesting to perform an EV analysis and to explore this framework. This chapter focuses on GEV analysis on annual maxima. Extension to POT or Point Processes is straightforward with tools provided in the text or in the code.
 %to provide the big picture to the reader  

\hyperref[sec:bayprelim]{Section \textbf{\ref{sec:bayprelim}}} introduces the Bayesian paradigm and presents its characteristics. \hyperref[sec:prior]{Section \textbf{\ref{sec:prior}}} presents an essential component of the Bayesian sphere, the priors that we will describe for GEV applications.
\hyperref[sec:baymcmc]{Section \textbf{\ref{sec:baymcmc}}} discusses several Monte Carlo algorithms that can be used to obtain a sample from the posterior. Then, \hyperref[sec:convbay]{Section \textbf{\ref{sec:convbay}}} presents diagnostics to assess the convergence of the algorithms in order to check i the reliability of the posterior's sample. If this is positive,
\hyperref[sec:bayinf]{Section \textbf{\ref{sec:bayinf}}} provides the Bayesian techniques to make inferences.
\hyperref[sec:ppd]{Section \textbf{\ref{sec:ppd}}} presents the posterior predictive distribution thats allows to handle predictions. Then, 
\hyperref[sec:modcompbay]{Section \textbf{\ref{sec:modcompbay}}} discusses tools for model's selection in a Bayesian setting. Finally,
\hyperref[sec:predacur]{Section \textbf{\ref{sec:predacur}}} introduces tools to validate models through information criteria.
Useful tools regarding basic Bayesian inference are left in \hyperref[appB]{Appendix \textbf{\ref{appB}}}.


This chapter is mostly based on \citet[sec. 9.1]{coles_introduction_2001},  \citet[chap.11]{beirlant_statistics_2006}, \citet[chap.13]{dey_extreme_2016} and \citet[chap.3]{ag_extremes_2013},  and other relevant articles.

\newpage
\include*{chap4}





\part{Experimental Framework : Extreme Value Analysis of Maximum Temperatures}\label{part:xp}
\thispagestyle{empty}

%In this part, we will focus on the application of the methods seen during the theoretical part. 

\chapter{Introduction to the Analysis}\label{chap:introana}
\vspace{-1cm}
\minitoc \thispagestyle{empty}
 \vspace{1cm}
 
Since we have theoretically defined useful concepts in EVT, we will now introduce the practical analysis of this thesis that consist of analyzing daily maximum temperatures in Uccle from 1901 to 2016.  
We have already showed the distribution of this data in Figure \ref{fig:pot_plot} to introduce the POT approach. This chapter will present an introductory analysis of the \emph{annual} maxima of these data, which will provide a convenient GEV modeling. We will then use several techniques to analyze the data before going further into the EV models in the following chapters. 

After a brief presentation of the repository which contains the R package created for this thesis and the structure for the scripts that contains the code that created all the analysis, this chapter briefly present the shiny applications created to enhance visualizations. \hyperref[sec:presuccle]{Section \textbf{\ref{sec:presuccle}}} will present data and its source. \hyperref[sec:firstana]{Section \textbf{\ref{sec:firstana}}} will first describe data and compare models to represent the data before going further on the trend analysis with splines derivatives in a Generalized Additive Model to assess the significance of the trend with correction for simultaneous tests and provide the first aspects in the issue of Climate Warming without using extreme models. 


This chapter will not explicitly use techniques presented in the previous chapters. It will be mostly based on \citet{ruppert_semiparametric_2003} for the model presented in \hyperref[sec:splines]{Section \textbf{\ref{sec:splines}}}. 
  

\newpage
\include*{chap5}



\chapter{Analysis in Block Maxima}\label{sec:anagev}
\minitoc \thispagestyle{empty}
 \vspace{1cm}
 
 This chapter introduces the core subject of this thesis, the stationary and nonstationary GEV analysis for the annual maximum temperatures in Uccle. Concepts borrowed from \hyperref[sec::1]{Chapter \textbf{\ref{sec::1}}} and \hyperref[sec::3]{Chapter \textbf{\ref{sec::3}}} will be used. POT analysis of \hyperref[sec::2]{Chapter \textbf{\ref{sec::2}}} will be mentioned but all results are kept in the code. 

In \hyperref[sec:xpstatio]{Section \textbf{\ref{sec:xpstatio}}}, we will present GEV inferences assuming stationarity which relies on \\ \texttt{1intro\_stationary.R} code from the \textbf{/Scripts-R/} folder of the \href{https://github.com/proto4426/PissoortThesis/}{repository}.
\hyperref[sec:xpnp]{Section \textbf{\ref{sec:xpnp}}} will introduce the nonstationary analysis with parametric models and relies on \texttt{2Nonstationary.R} code, while \hyperref[sec:nnxp]{Section \textbf{\ref{sec:nnxp}}} allows for more complex models from deep architectures and relies on \texttt{2NeuralsNets.R} code. 

Although some Bayesian concepts will be used in this section such as use of \emph{prior distributions} for the EVI to limit its domain when estimating it with a likelihood-based method, or to regularize weights of Neural Networks in \hyperref[sec:nnxp]{Section \textbf{\ref{sec:nnxp}}}, we will still call all these methods as "frequentists".
A strict Bayesian analysis will be made in \hyperref[sec:anabayes]{next Chapter \textbf{\ref{sec:anabayes}}} and comparisons will be provided.

\newpage
\include*{chap6}


%%%%%%%%%%%%%%%%%%%%%%%%
\iffalse
\chapter{Stationary and Nonstationary GEV Analysis}\label{sec:ananonsta}
\minitoc \thispagestyle{empty}
 \vspace{1cm}
\include*{chap8}
\fi
%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Bayesian Analysis in Block Maxima}\label{sec:anabayes}
\minitoc \thispagestyle{empty}
 \vspace{1cm}
 
Bayesian analysis is used more and more everywhere. For example in this text,  \hyperref[chap:introana]{Chapter \textbf{\ref{chap:introana}}} used a simulation-based Bayesian approach to compare coverage properties of pointwise and simultaneous confidence intervals, while \hyperref[sec:nnxp]{Section \textbf{\ref{sec:nnxp}}} used priors to constrain the domain of the shape parameter or to penalize weights in a neural network's architecture. %This chapter aims at presenting an other 

After briefly presenting the available methods in \hyperref[sec:meth]{Section \textbf{\ref{sec:meth}}} and discussing our choice, \hyperref[sec:baystatio]{Section \textbf{\ref{sec:baystatio}}} will present the GEV stationary model in order to compare the three leading algorithms by Bayesian's practitioners for sampling with Markov Chain Monte Carlo. \hyperref[sec:baycomp]{Section \textbf{\ref{sec:baycomp}}} will focus on the comparison of nonstationary models with predictive accuracy criteria in order to select the model that will be analyzed in 
\hyperref[sec:bay_nonsta]{Section \textbf{\ref{sec:bay_nonsta}}}. Convergence issues will be addressed, with both quantitative criteria and visual demonstrations, and comparisons with the results obtained in the last chapter will be provided. 
\hyperref[sec:rem]{Section \textbf{\ref{sec:rem}}} will conclude the chapter by discussing other possibles techniques and will also provide a visual summary of all the credible (or confidence) intervals obtained for the parameters during this whole text obtained during this thesis.

This analysis relies on all the scripts with filenames starting with "\texttt{Bayes\_}" in the \textbf{/Scripts-R/} folder of the \href{https://github.com/proto4426/PissoortThesis/}{repository}. \texttt{Bayes\_own\_gev.R} is especially useful to retrieve the outputs of the chapter.  All the created functions are used and made available in \textbf{/R/}\texttt{BayesFunc.R} and can be used from the package. Moreover,
the \texttt{/vignettes/Summary\_Bayesian.html} file in the \href{https://github.com/proto4426/PissoortThesis/}{repository} presents the analysis in more details.

\newpage
\include*{chap7}




\addcontentsline{toc}{chapter}{Conclusion}
\chapter*{Conclusion}
\thispagestyle{empty}

\iffalse
Dans l'introduction et dans la conclusion, ce serait bien de mieux préciser, de façon structurée :
- la question ou les questions de recherche
- les données
- la méthodologie (bien motiver tes choix de méthodes)
- les réponses trouvées aux questions énoncées initialement
\fi

This thesis aimed at statistically assessing the presence of a nonstationary model using a sequence of annual maximum temperatures in Uccle from $1901$ to $2016$  and applying the Extreme Value Theory. Official data was used to evaluate the effects of climate warming.
To this end, this thesis is divided into two parts to make a clear separation between the literature review (\hyperref[part1]{Part \textbf{\ref{part1}}}) and the application of the methods (\hyperref[part:xp]{Part \textbf{\ref{part:xp}}}).

\hyperref[part1]{Part \textbf{\ref{part1}}} stars by presenting the approach of block maxima in \hyperref[sec::1]{Chapter \textbf{\ref{sec::1}}} which models the extremes that occur inside a block. It introduces the GEV distribution and its parameters that form at the basis of the nonstationary models.
The second approach of modeling extremes discussed in \hyperref[sec::2]{Chapter \textbf{\ref{sec::2}}} aims to model the extremes that exceed a certain threshold.
Since it was decided to work only with annual maxima due to space constraints, this thesis puts more emphasis on the first approach. In order to evaluate the form of the nonstationarity in the sequence,
\hyperref[sec::3]{Chapter \textbf{\ref{sec::3}}} delivers tools that allows the analysis to go beyond the restrictive independence assumption of the first two chapters. This provides the tools to consider different parametric models for the GEV parameters that will form the basis of the nonstationary analysis, as well as a flexible approach using Neural Networks to surpass  the restrictive parametric assumption.
\hyperref[sec::bayesian]{Chapter \textbf{\ref{sec::bayesian}}} presents the Bayesian analysis applied to the world of extremes which provides us inferential methods that better account for both  estimation and prediction uncertainty. 

In \hyperref[part:xp]{Part \textbf{\ref{part:xp}}},  \hyperref[chap:introana]{Chapter \textbf{\ref{chap:introana}}} introduces the analysis with other methods not from EVT to provide initial insights on the analysis of the trend. Although the trend were significant from a simple linear regression, simultaneous intervals based on splines derivatives of a Generalized Additive Model highlighted that the trend is not significant over time, whilst pointwise intervals emphasized the accelerating trend of the annual maxima in the last $40$ years. This accelerating behavior of the annual maxima at the end of the sequence was confirmed at the end of \hyperref[sec:anagev]{Chapter \textbf{\ref{sec:anagev}}} by a bootstrap aggregated Neural Network which used a deep nonlinear model that address overfitting. However, prior to this, this thesis identifies that the best and most parsimonious parametric GEV model had only a linear trend on the location parameter. This is the same model selected by the flexible modeling with Neural Network, according to information criteria to prevent overfitting among a large number of models. \hyperref[sec:anabayes]{Chapter \textbf{\ref{sec:anabayes}}} finally confirms  with predictive accuracy criteria that the nonstationary GEV model with a simple linear model on the location parameter is the best among some carefully chosen parametric models. Hence,
% \textbf{we can conclude with the support of three intrinsically different modeling techniques relying on the GEV distribution that there is a linear trend on the location of the annual maxima in Uccle.} %However, caution should always be put when extrapolating from
\vspace{.2cm}
\begin{tcolorbox}
	this thesis concludes, based upon the outcomes of three intrinsically different modeling techniques relying on the GEV distribution that there is a linear trend on the location of the annual maxima in Uccle.
\end{tcolorbox}
It is important to highlight that a climatologist from IRM noted that artificial warming has been observed on cities' stations which were significantly less urbanized $100$ years ago, including Uccle. This,  with the limitations we specified in \hyperref[part:xp]{Part \textbf{\ref{part:xp}}}, means that the conclusions and interpretations drawn in this thesis should be tempered by great caution.
\newline

Time and space constraints did not allow this thesis to consider some methods : 

\begin{itemize} 
\item The \emph{Bayesian Neural Networks}n from the pioneering thesis of \citet{Neal_1996_bay} : these are now widely used for their high level of flexibility. For this thesis and to make it simple, it would have meant roughly combining the flexibility of the GEV-CDN framework of \hyperref[sec:nnxp]{Sections \textbf{\ref{sec:nnxp}}} and \hyperref[sec:gevcdn]{ \textbf{\ref{sec:gevcdn}}} (in the sense of being capable of modeling any relationships)  with the flexibility of the  Bayesian analysis of \hyperref[sec::bayesian]{ Chapters \textbf{\ref{sec::bayesian}}} and \textbf{\ref{sec:anabayes}} (in the sense of being, for example, able to tune a vast amount of information). Hence, it would have been able to surpass the restrictive assumption of parametric models that have been considered in the Bayesian chapters.

%Even if we were not able to execute some dangerous methods such as the Hamiltonian Monte Carlo or the computation of the Bayes factor for example, this thesis allowed to learn by doing 

\item This thesis considers time as the sole covariate to explain the changes in the extreme temperatures. Other covariates could have been included to improve the nonstationary analysis. For example, the \emph{Southern Oscillation Index} (a proxy for El Niño), the $\text{CO}_2$ level, etc.
However, these alternative covariates are (highly) time-dependent, and linking to a climatological covariate makes the
extrapolation into the future more difficult as one would need to extrapolate the covariate as well. 

\item Since the IRM is able to provide temperature measurements in real-time, it would be feasible to automate all the methods and the analysis by using similar tools (e.g. in the R package or in a Shiny application) in order to automatically take into account each new observations, providing live updates of the statistical models.

\item \citet{Ribes2017} noticed that winter is becoming warmer in the context of climate warming.
Computationally speaking, it would require only a few changes in order to undertake the same analysis as was undertaken with maxima. Here again, an automated method would be very easy and worth implementing. These different analysis have been introduced a then end of \texttt{1intro\_stationary.R} and the beginning of \texttt{2nonstationary.R}, but we did not use all the methods on these new data.
\end{itemize}

Finally, this thesis analyzes the increasing behavior of extreme temperatures, but it does study the causality of this change nor make an extensive analysis of the anthropogenic nature of the global warming, which is often the big issue.

\thispagestyle{empty}

%Finish (Bayesian) documentation in the package.


%\clearpage
\addcontentsline{toc}{part}{Appendix}
\part*{Appendix}
\appendix

\include*{appendix}




\bibliographystyle{ieeetr}
\setlength{\parindent}{5em}
\setlength{\parskip}{2em}
\renewcommand{\baselinestretch}{4.0}

\bibliography{zotero1}

\end{document}