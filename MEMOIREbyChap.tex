\documentclass[11pt,a4paper,openany, twosided]{book}
\makeatletter
\title{MEMOIRE}
\makeatletter
\newcommand{\crossout}[1]{%
\begingroup
\settowidth{\dimen@}{#1}%
\setlength{\unitlength}{0.05\dimen@}%
\settoheight{\dimen@}{#1}%
\count@=\dimen@
\divide\count@ by \unitlength
\count0=20 \count4=\count@\\
\loop
\count2=\count0 % keep a copy
\divide\count2\count4 \multiply\count2\count4
\ifnum\count2<\count0
\advance\count0 -\count2 % the remainder
\count2=\count0
\count0=\count4
\count4=\count2
\repeat
\count0=20 \divide\count0\count4
\count2=\count@ \divide\count2\count4
\begin{picture}(0,0)
\put(0,0){\line(\count0,\count2){20}}
\put(0,\count@){\line(\count0,-\count2){20}}
\end{picture}%
#1%
\endgroup
}
\makeatother
\newcommand\independent{\protect\mathpalette{\protect\independenT}{\perp}}
\def\independenT#1#2{\mathrel{\rlap{$#1#2$}\mkern2mu{#1#2}}}

\makeatletter % No page counter for \part
\renewcommand\part{%
	\if@openright
	\cleardoublepage
	\else
	\clearpage
	\fi
	\thispagestyle{empty}%   % Original »plain« replaced by »emptyx
	\if@twocolumn
	\onecolumn
	\@tempswatrue
	\else
	\@tempswafalse
	\fi
	\null\vfil
	\secdef\@part\@spart}
\makeatother

\usepackage{scalerel,stackengine}
\stackMath
\newcommand\reallywidehat[1]{%
	\savestack{\tmpbox}{\stretchto{%
			\scaleto{%
				\scalerel*[\widthof{\ensuremath{#1}}]{\kern-.6pt\bigwedge\kern-.6pt}%
				{\rule[-\textheight/2]{1ex}{\textheight}}%WIDTH-LIMITED BIG WEDGE
			}{\textheight}% 
		}{0.5ex}}%
	\stackon[1pt]{#1}{\tmpbox}%
}


\usepackage{newclude} % delete \newpage with \include*{}
\usepackage{booktabs,multirow}% 

\usepackage[dvipsnames]{xcolor}
\usepackage[utf8]{inputenc} 
\usepackage[T1]{fontenc} 
%\usepackage[sc]{
\usepackage{lmodern}
%\usepackage[nomath]{kpfonts} % coment to return to lpmodern complet
\usepackage{libertine}%  serif and sans 
%\usepackage[scaled=0.85]{beramono}%% mono
\usepackage{setspace}
\linespread{1.05}

\usepackage[english]{babel}
\usepackage[a4paper]{geometry}
\usepackage{graphicx}
\usepackage[font=small,labelfont={bf,it},textfont=it]{caption}
\usepackage{csquotes}
\usepackage{subcaption}
\usepackage{pdfpages}
\usepackage[flushleft]{threeparttable}
\usepackage{multirow}
\usepackage{footnote}
\makesavenoteenv{array}
\usepackage[bottom]{footmisc}
\usepackage{tabularx, booktabs}
\newcolumntype{Y}{>{\centering\arraybackslash}X}
\usepackage{listings}
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\usepackage{longtable}

\usepackage{sidecap}
\usepackage{pdflscape}
\usepackage{wrapfig}
\usepackage{listings}
\usepackage{babel,blindtext}
\usepackage{lipsum}
%\usepackage{slashbox}
\usepackage{dashrule}
\usepackage{hhline}
\usepackage{color}
%\usepackage{subfig}
\usepackage{graphicx}


\usepackage{amsmath} % Les math
\makeatletter
\let\reftagform@=\tagform@
\def\tagform@#1{\maketag@@@{(\ignorespaces\textcolor{blue}{#1}\unskip\@@italiccorr)}}
\renewcommand{\eqref}[1]{\textup{\reftagform@{\ref{#1}}}}
\makeatother
\usepackage{amssymb} % Symboles math
\usepackage{esvect} % Vecteurs
\usepackage[amssymb]{SIunits}
\usepackage{eurosym}
\usepackage{mathrsfs}
\usepackage{dcolumn}
\usepackage{pifont}
\usepackage{amsthm}

\usepackage[breaklinks,colorlinks]{hyperref}
\hypersetup{
colorlinks=true,linkcolor=blue,%citecolor=CornflowerBlue,naturalnames=true,hypertexnames=false,
	filecolor=magenta,      
	urlcolor=cyan,
	citecolor=ForestGreen,
}
\usepackage{etoolbox}


\usepackage[ruled,vlined]{algorithm2e}
\usepackage{mathtools}

\newcommand{\expect}{\operatorname{E}\expectarg}
\DeclarePairedDelimiterX{\expectarg}[1]{[}{]}{%
	\ifnum\currentgrouptype=16 \else\begingroup\fi
	\activatebar#1
	\ifnum\currentgrouptype=16 \else\endgroup\fi
}
\newcommand{\innermid}{\nonscript\;\delimsize\vert\nonscript\;}
\newcommand{\activatebar}{%
	\begingroup\lccode`\~=`\|
	\lowercase{\endgroup\let~}\innermid 
	\mathcode`|=\string"8000
}
\newlength{\mylen}  % change size of items
\setbox1=\hbox{$\bullet$}\setbox5=\hbox{\normalsize$\bullet$}
\setlength{\mylen}{\dimexpr0.5\ht1-0.5\ht2}
\makeatletter
% Patch case where name and year are separated by aysep
\patchcmd{\NAT@cite}
{\@cite\NAT@hyper@{%
		\NAT@nmfmt{\NAT@nm}%
		\hyper@natlinkbreak{\NAT@aysep\NAT@spacechar}{\@citeb\@extra@b@citeb}%
		\NAT@date}}
{\@cite\NAT@nmfmt{\NAT@nm}%
	\NAT@aysep\NAT@spacechar\NAT@hyper@{\NAT@date}}{}{}

% Patch case where name and year are separated by opening bracket
\patchcmd{\NAT@cite}
{\@cite\NAT@hyper@{%
		\NAT@nmfmt{\NAT@nm}%
		\hyper@natlinkbreak{\NAT@spacechar\NAT@@open\if#1\else#1\NAT@spacechar\fi}%
		{\@citeb\@extra@b@citeb}%
		\NAT@date}}
{\@cite\NAT@nmfmt{\NAT@nm}%
	\NAT@spacechar\NAT@@open\if#1\else#1\NAT@spacechar\fi\NAT@hyper@{\NAT@date}}
{}{}

\makeatother

\usepackage{datetime} 
\usepackage{bm}
\usepackage{scalerel,stackengine}
\usepackage{pbox}
\usepackage{vmargin}            
\setmarginsrb{2,5cm}{2,7cm}{2,5cm}{2,5cm}{0cm}{1cm}{0cm}{1cm}
\rmfamily
%\DeclareFontShape{T1}{lmr}{b}{sc}{<->ssub*cmr/bx/sc}{}
%\DeclareFontShape{T1}{lmr}{bx}{sc}{<->ssub*cmr/bx/sc}{}

\DeclareMathOperator*{\argminA}{arg\,max} % Jan Hlavacek
\DeclareMathOperator*{\argminB}{argmax}   % Jan Hlavacek
\DeclareMathOperator*{\argminC}{\arg\max}   % rbp

\newcommand{\argmaxD}{\arg\!\max} % AlfC

\newcommand{\argminE}{\mathop{\mathrm{argmin}}}          % ASdeL
\newcommand{\argminF}{\mathop{\mathrm{argmin}}\limits} 

\usepackage{fancyhdr}
\usepackage{afterpage}

\fancypagestyle{plain}{\fancyhf{}}
\pagestyle{fancy}
\fancyfoot{}
\cfoot{\thepage}
\fancyhead[RO,LE]{\thepage}
\fancyhead[LO]{\leftmark}
\fancyhead[RE]{\rightmark}
\renewcommand{\headrulewidth}{.6pt}

\iffalse
\copypagestyle{memoirStylePages}{headings}
\makerunningwidth{memoirStylePages}{\textwidth}
\makeheadrule{memoirStylePages}{\textwidth}{\normalrulethickness}
\pagestyle{memoirStylePages}
\fi


\pagenumbering{roman}
\newcommand{\bib}{\par\noindent\hangindent=0.5 true cm \hangafter=1}

\makeatletter  % rm pg number in bottom
\let\@oddfoot\@empty
\let\@evenfoot\@empty
\makeatother
\usepackage{appendix}
%\usepackage[style=apa,backref=true,backend=biber,natbib=true,hyperref=true]{biblatex} 
\let\origappendix\appendix % save the existing appendix command
\renewcommand\appendix{\clearpage\pagenumbering{Roman}\origappendix}


%\addbibresource{zotero.bib.bib}
\usepackage[sort, square, comma]{natbib}
%\usepackage{natbib}
\bibliographystyle{abbrvnat}
\setcitestyle{authoryear, open = {[}, close={]} }

%\setcitestyle{square}
%\setcitestyle{authoryear, open={[},close={)]}}
%\usepackage{apacite}
%\usepackage{cite}
%\usepackage[backend=biber]{biblatex}
\usepackage{bbm}
\usepackage{enumitem}
\usepackage{minitoc}

\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
%\theoremstyle{definition}
\newtheorem{definition}{Definition}[chapter]
%\renewcommand*{\proofname}{\boxed{Proof}}
\usepackage{thmtools}

\newcommand*{\QEDB}{\hfill\ensuremath{\triangle}}%
\newcommand*{\QEDA}{\hfill\ensuremath{\blacksquare}}%

\AtEndEnvironment{theorem}{\null\hfill\qedsymbol}%
\AtEndEnvironment{definition}{\null\hfill\QEDB}%
%\declaretheorem[style=definition,qed=$\triangle$,sibling=definition]{definition}
%\declaretheorem[style=definition,qed=$\triangle$,sibling=definition]{theorem}
\newtheorem{exe}{Theorem}
\setcounter{exe}{-1}


\usepackage{mathtools}
\DeclarePairedDelimiter\abs{\lvert}{\rvert}
\DeclarePairedDelimiter\norm{\lVert}{\rVert}

\usepackage{multirow,bigdelim}
\usepackage{tcolorbox}
\usepackage{adjustbox}
\usepackage{dashbox}
\usepackage{todonotes}

\newcommand{\abbrlabel}[1]{\makebox[3cm][l]{\textbf{#1}\ \dotfill}}
\newenvironment{abbreviations}{\begin{list}{}{\renewcommand{\makelabel}{\abbrlabel}}}{\end{list}}


\usepackage{tikz}
\usetikzlibrary{matrix,chains,positioning,decorations.pathreplacing,arrows}
%\defbeamertemplate{itemize item}{tikzarrow}{\tikz{\node[single
%		arrow,scale=0.2,inner sep=2ex,fill] at (0,0) {};}}

\tikzset{myarrow/.style={
		draw,
		fill=Emerald,
		single arrow,
		minimum height=5.5ex,
		single arrow head extend=1ex
	}
}
\newcommand{\arrowright}{%
	\tikz [baseline=-1ex]{\node [myarrow,rotate=0] {};}
}
\setlength{\parskip}{.2em}

\usepackage{afterpage}

\newcommand\blankpage{%
    \null
    \thispagestyle{empty}%
    \addtocounter{page}{-1}%
    \newpage}


\setcounter{tocdepth}{3}
\setcounter{secnumdepth}{4}
\setcounter{minitocdepth}{4}

% Chapter head 
\makeatletter
\def\thickhrulefill{\leavevmode \leaders \hrule height 1ex \hfill \kern \z@}
\def\@makechapterhead#1{%
  {\parindent \z@ \raggedright
    \reset@font
    \hrule
    \vspace*{10\p@}%
    \par
    \Large \scshape \@chapapp{} \Huge\bfseries \thechapter
    \par\nobreak
    \vspace*{10\p@}%
    \hrule
    \par
    \vspace*{1\p@}%
    \hrule
    %\vskip 40\p@
    \vspace*{20\p@}
    \Huge \bfseries #1\par\nobreak
    \vskip 70\p@
  }}

\begin{document}
\thispagestyle{empty}


\begin{center}
	{\LARGE    UNIVERSITE CATHOLIQUE DE LOUVAIN} \\
	\vspace{0.2cm}
	{\large FACULTE DES SCIENCES} \\
	\vspace{0.2cm}
	{\Large ECOLE DE STATISTIQUE, BIOSTATISTIQUE \\
		\vspace{0.1cm}
		ET SCIENCES ACTUARIELLES }\\
\end{center}
\vfill

%\begin{figure}[H]
\begin{center}  \hspace*{-10mm} 
	\includegraphics[height = 3.5cm]{lsba.jpg}
\end{center}
%\end{figure}

\thispagestyle{empty}

\vfill


\begin{center}
	{\Large \textsc{Temporal Analysis of the Evolution of Extreme Values Using Climatological Data}}
	
\end{center}


\vfill

\begin{center}[]
	\begin{minipage}[c]{.45\linewidth}
		\begin{tabular}{ll}
			\vspace{0.2cm}
			Promoteur : & Johan \textsc{Segers} \\
			\vspace{0.2cm}
			Lecteurs : & Anna \textsc{Kiriliouk}\\
			\vspace{0.2cm}
			& Michel \textsc{Crucifix}
		\end{tabular}
	\end{minipage} \hfill
	\begin{minipage}[c]{.45\linewidth}
		\begin{tabularx}{\linewidth}{p{\textwidth}}
			Mémoire présenté en vue de \hbox{l'obtention} du \\   \vspace{0.1cm} Master en statistiques, orientation générale \\   \vspace{0.1cm} par :
			\textbf{Antoine \textsc{Pissoort}}
		\end{tabularx}
	\end{minipage}
\end{center}

\vspace{1,5cm}



\begin{center}
	{\large Juin 2017}
\end{center}
\thispagestyle{empty}
\newpage


%\centering
\topskip0pt
\vspace*{\fill}
%\addcontentsline{toc}{chapter}{Abstract}%
\section*{\centering Abstract}
\begin{tcolorbox}%[colback=SeaGreen!75!white]
This thesis provides an in-depth nonstationary analysis on recent official records of annual maximum temperatures in order to statistically evaluate global warming. Relying on various modeling techniques coming from the Extreme Value Theory, we have shown that a nonstationary extreme value Weibull model with a linear model on the location parameter is the preferred model to explain the data among a vast number of parametric and nonparametric models, according to various and carefully chosen information and predictive criteria. We have then proven that the scale is not significantly affected. While this lead us to consider that the global warming is linear in the location of the annual maximum temperatures, other modeling techniques implying splines's derivatives in a generalized additive model had previously shown that the trend on the annual maxima were not simultaneously significant over time.
While developing theoretical backgrounds on these state-of-the-art methods, this thesis carefully presents the application of these methods that have been conveniently gathered into a repository and R package, enabling efficient automated analysis for the future.

\thispagestyle{empty}
\end{tcolorbox}

\vspace{.3cm}

\paragraph*{Keywords} $\bullet$ Extreme Value Theory   $\bullet$ Generalized Extreme Value  $\bullet$ Generalized Pareto Distribution $\bullet$ Nonstationary analysis $\bullet$ Bayesian inference   $\bullet$ Generalized Additive Models $\bullet$ Splines smoothing  $\bullet$ Conditional Density Networks $\bullet$ Bootstrapping methods $\bullet$ Parallel computing $\bullet$ R package $\bullet$ Shiny applications
\vspace*{\fill}

\newpage


%\afterpage{\cfoot{\thepage}}


\newenvironment{acknowledgements}%
{\thispagestyle{empty}\null\vfill\begin{center}%
\bfseries Acknowledgements\end{center}}%
{\vfill\null}
%\addcontentsline{toc}{chapter}{Acknowledgements}%
\begin{acknowledgements}
	\textit{I would first like to thank my thesis supervisor Johan Segers for all his help and his guidance during this whole year. The repeated appointments we have had   }
	\newline
	
	\textit{I also would like to thank the "Institut Royal de Météorologie" (IRM) of Belgium for his help and his guidance but also for his provided quality datasets.}
	\newline
	
	\textit{A bit less usual, I would like to thank the open source community such as R or LaTeX can benefit. For me and for a number of student, it has been a nonnegligable source of ideas and the most efficient source of learning.  }
	\newline
	
	\textit{A bit less usual, but I would like to thank in particular this thesis that permits me to acquire a vast knowledge on various subjects and to develop expertises in the R language. %$25$ credits that are undoubtedly worth the hundred other for this master. 
		}
   	\newline
   	
	\textit{Finally, I want to thank my family and my friends, but also Bernadette and Michel for their support and all the time I have spent  writing in their house for my thesis but also during my whole academic studies.}
	
	\thispagestyle{empty}
\end{acknowledgements}


\afterpage{\blankpage}


\thispagestyle{empty}
\dominitoc
\thispagestyle{empty}
\tableofcontents
\thispagestyle{empty}
\newpage
\thispagestyle{empty}
\listoffigures
\thispagestyle{empty}
\listoftables
\thispagestyle{empty}

\newpage


\chapter*{List of Abbreviations}
%\addcontentsline{toc}{chapter}{List of Abbreviations}
\thispagestyle{empty}
For convenience, we place a list of all the abbreviations we will use in the text. However, these will always be defined in their first occurrence in the text.\\

\begin{center}
\begin{abbreviations}
	\item[BMA] Bayesian Model Averaging
	\item[DA] Domain of Attraction
	\item[df]\label{df}  (cumulative) distribution function
	\item[EVI] Extreme Value Index ($\xi$)
	\item[EVT] Extreme Value Theory
	\item[GEV] Generalized Extreme Value
	\item[GML] Generalized Maximum Likelihood
	\item[GPD] Generalized Pareto Distribution %(function)
	\item[MC(MC)] Marko Chain (Monte Carlo)
	\item[MH] Metropolis-Hastings 
	\item[ML] Maximum Likelihood 
	\item[MLE] Maximum Likelihood Estimator
	\item[NN] Neural Network
	\item[PP(D)] Posterior Predictive (Distribution)
	\item[TN] Temperature miNimum
	\item[TX] Temperature maXimum
	
\end{abbreviations}
\end{center}


\renewcommand\labelitemi{\normalsize$\bullet$}



\afterpage{\blankpage}


\addcontentsline{toc}{chapter}{Introduction}
\chapter*{Introduction}
	%Presentation of the Analysis }
\pagenumbering{arabic}
\thispagestyle{empty}


Extreme Value Theory (EVT) is concerned with the statistical characterization of \emph{extreme} events. 
With various other applications such as risk analysis, finance or insurance, this thesis aims at applying the EVT on the broad environmental area, in particular with a meteorological application. Although the other applications can have strong impacts on people lives for example with financial crisis, environmental extremes can often have more dramatic consequences.
Moreover, the increase in weather extremes in the past decade has brought again more importance to this subject.

Think for instance at the major drought events that have been recorded in the past few years in Ethiopia, Australia, United Stated, Eurasia, etc. For example, Pakistan experienced the worst flooding in $80$ years resulting in over two thousands casualties and twenty million people affected. The $2003$ European heatwave killed approximately seventy thousands people, which is more than ten times the number of killed people in September 11 attacks. 


Henceforth, the need for EVT in order to analyze these extreme events is compelling.
Our application comes from an official dataset provided by the "Institut Royal of Météorologie" (IRM) of Uccle. 
Since the problem facing climate change evidence is often the lack of reliable past data to compare with, we chose a homogeneous dataset with annual temperatures from $1901$ to $2016$. 


Following \citet{kharin_changes_2007}, we can anticipate that climate change affects the extreme weather. Aware of the existence of the temporal increase of the annual maxima but having no prior idea on the form of this evolution, we can summarize the research problem of this thesis as : 
\vspace{0.1cm}
\begin{tcolorbox}%[colback=SeaGreen!75!white]
	Statistically evaluating the nonstatonarity of the sequence of annual maxima in order to assess the climate warming and predict the extreme events associated. 
\end{tcolorbox}
To this end, we can model these \emph{extremes} with two different approaches : 

\begin{itemize}
	\item Either as maximum observations that occur inside nonoverlapping \emph{blocks} of equal size.
	In \hyperref[sec::1]{Chapter \textbf{1}} we will present the method of \emph{block-maxima} and derive the Generalized Extreme Value (GEV) distribution.
	\item Or as observations that \emph{exceed} a certain high \emph{threshold}. Often regarded as more efficient as it can use more observations, this method will be presented in  \hyperref[sec::2]{Chapter \textbf{2}} and is called the \emph{peaks-over-threshold} approach, from which is derived the Generalized Pareto Distribution.
\end{itemize}
Since we deal with an annual sequence, i.e.  maxima over a block of 1 year, the first approach will be prominent.
While the first chapters restricts the analysis to independent sequences, \hyperref[sec::3]{Chapter \textbf{3}} we will get into the heart of the matter by considering dependent sequences and present tools to model nonstationary sequences.
Willing to go beyond the somewhat restrictive parametric inferential methods in EVT, we considered a novel flexible model relying on a Neural Networks framework, in order to assess the nonstationarity with a significantly higher number of possible models with an efficient method. 
\hyperref[sec::bayesian]{Chapter \textbf{\ref{sec::bayesian}}} will present the Bayesian methods that can be applied for our purpose, and that will help us to better take the estimation and predictive uncertainty into account.

The second part will apply these methods on the annual maxima in Uccle. It will start by an in-depth introductory trend analysis on these maxima in \hyperref[chap:introana]{Chapter \textbf{\ref{chap:introana}}} in order to strictly evaluate their evolution over time, both with pointwise and simultaneous confidence intervals. 
\hyperref[sec:anagev]{Chapter \textbf{\ref{sec:anagev}}} will present the application of the EVT with the block-maxima approach with strong emphasis on methods to make a nonstationary GEV analysis.
\hyperref[sec:anabayes]{Chapter \textbf{\ref{sec:anabayes}}} will conclude the analysis with Bayesian methods, bringing its flexibility by means of new implemented methods.

\thispagestyle{empty}



\begin{center}
\part{Theoretical Framework : Extreme Value Theory}\label{part1}
\end{center}
%\pagestyle{fancy}


\setcounter{mtc}{1}
\chapter{Method of Block Maxima} \label{sec::1}
\vspace{-1cm}
\minitoc \thispagestyle{empty}
 \vspace{1cm}

This chapter introduce the basics of EVT by considering the \textit{block-maxima} approach. This approach aims at modeling the extremes inside a predefined block. 
After defining useful concepts in 
\hyperref[sec::1.1]{Section \textbf{1.1}} to introduce the emergence of this theory, we will get into the leading theorem of EVT in \hyperref[sec:extrtypethm]{Section \textbf{\ref{sec:extrtypethm}}}. \hyperref[sec::appconcrete]{Section \textbf{\ref{sec::appconcrete}}} will present some mathematical applications and \hyperref[sec:mda]{Section \textbf{\ref{sec:mda}}} conditions  of this theorem in order to visualize the implications of the extremal theorem and the characterizations of the underlying distributions. \hyperref[rlgev]{Section \textbf{\ref{rlgev}}} will introduce key concepts of inference in EVT which will be presented in a general (and frequentist) way in  \hyperref[sec::gevinfernce]{Section \textbf{\ref{sec::gevinfernce}}}. Finally, \hyperref[sec:diag]{Section \textbf{\ref{sec:diag}}} provides some tools to assess the accuracy of the fitted model.

This chapter is mostly based on \citet[chap.3]{coles_introduction_2001}, \citet[chap.2]{beirlant_statistics_2006} and \citet[chap.1-4]{reiss_statistical_2007}, and other relevant articles.

\newpage
\include*{chap1}



\chapter{Peaks-Over-Threshold Method}\label{sec::2}
\vspace{-1cm}
\minitoc \thispagestyle{empty}
 \vspace{1cm}

This chapter will focus on a major approach of EV models by modeling only the excess over a certain threshold. This approach is very popular in practice as it can handle all the extremes with more flexibility and not only the maximum of one block. From this, numerous techniques have emerged and we will navigate the main ideas.

In \hyperref[sec::2.1]{Section \textbf{\ref{sec::2.1}}}, we will introduce the approach that will help us 
to formally characterize the resulting distribution of interest in \hyperref[sec:charac_gpd]{Section \textbf{\ref{sec:charac_gpd}}}. \hyperref[sec:rl_gpd]{Section \textbf{\ref{sec:rl_gpd}}} will present the concept of return levels applied to this concept. We will then assess the maximum temperature threshold in a statistical sense in \hyperref[sec:thresh_selec]{Section \textbf{\ref{sec:thresh_selec}}} by reviewing available methods, with common suggested thresholds of $25^{\circ} c$ or $30^{\circ} c$ from meteorologists.

Unfortunately, the resulting analysis of this chapter will not be presented in \hyperref[part:xp]{Part \textbf{\ref{part:xp}}} because it would have made the text too voluminous. Empirical results (code and html reports) will remain available in the \href{https://github.com/proto4426/PissoortThesis/}{repository}\footnote{\url{https://github.com/proto4426/PissoortThesis/}}(see \hyperref[appgit]{Appendix \textbf{\ref{appgit}}}). Moreover, \emph{point process} will not be covered for the same reason but we remind that this is a powerful and flexible method that summarizes the two techniques considered in the two first chapters, and it should then not be missed. 

This chapter is mostly based on \citet[chap.4 and 7]{coles_introduction_2001}, \citet[chap.4]{beirlant_statistics_2006}, \citet[chap.5]{reiss_statistical_2007} and 
\citet[chap.5]{embrechts_modelling_2011},
 and other relevant articles.

\newpage
\include*{chap2}



\chapter{Relaxing The Independence Assumption}\label{sec::3}
\vspace{-1cm}
\minitoc\thispagestyle{empty}
 \vspace{1cm}
 
In most environmental applications, the independence assumption made in the first chapters is questionable and never completely fulfilled. From hydrological processes as stated in \citet{milly_climate_2008} to temperature data to demonstrate climate warming, such theoretical assumptions that have been previously made are not sustainable in practice. \hyperref[sec:statio]{Section \textbf{\ref{sec:statio}}} will provide tools that enable EV models to hold in presence of a limited long-range dependence.
\hyperref[nstatio]{Section \textbf{\ref{nstatio}}} will allow EV modeling under nonstationary processes that will enable us to study the possible increasing behavior of the maximum temperatures. \hyperref[sec:returnlvlnstatio]{Section \textbf{\ref{sec:returnlvlnstatio}}} will redefine return levels under those less restricted cases, and finally  \hyperref[sec:gevcdn]{Section \textbf{\ref{sec:gevcdn}}} will introduce a new flexible way to model nonstationary extremes under a redefined Multi Layer Perceptron framework with inferential techniques minimizing the risk of overfitting.


This chapter is mostly based on \citet[chap.5-6]{coles_introduction_2001}, \citet[chap.10]{beirlant_statistics_2006} and \citet[chap.7]{reiss_statistical_2007}, and other relevant articles.
\newpage
\include*{chap3}




\chapter{Bayesian Extreme Value Theory}\label{sec::bayesian}
\vspace{-1.5cm}
\minitoc\thispagestyle{empty}
 \vspace{0.1cm}


Whilst sometimes criticized for the introduction of some subjectivity, the Bayesian paradigm is increasingly adopted by practitioners for its benefits. In this case, Bayesian inference is interesting to perform an EV analysis and to explore this framework. This chapter focuses on GEV analysis on annual maxima. Extension to POT or Point Processes is straightforward with tools provided in the text or in the code.
 %to provide the big picture to the reader  

\hyperref[sec:bayprelim]{Section \textbf{\ref{sec:bayprelim}}} introduces the Bayesian paradigm and presents its characteristics. \hyperref[sec:prior]{Section \textbf{\ref{sec:prior}}} presents an essential component of the Bayesian sphere, the priors that we will describe for GEV applications.
\hyperref[sec:baymcmc]{Section \textbf{\ref{sec:baymcmc}}} discusses several Monte Carlo algorithms that can be used to obtain a sample from the posterior. Then, \hyperref[sec:convbay]{Section \textbf{\ref{sec:convbay}}} presents diagnostics to assess the convergence of the algorithms in order to check i the reliability of the posterior's sample. If this is positive,
\hyperref[sec:bayinf]{Section \textbf{\ref{sec:bayinf}}} provides the Bayesian techniques to make inferences.
\hyperref[sec:ppd]{Section \textbf{\ref{sec:ppd}}} presents the posterior predictive distribution thats allows to handle predictions. Then, 
\hyperref[sec:modcompbay]{Section \textbf{\ref{sec:modcompbay}}} discusses tools for model's selection in a Bayesian setting. Finally,
\hyperref[sec:predacur]{Section \textbf{\ref{sec:predacur}}} introduces tools to validate models through information criteria.
Useful tools regarding basic Bayesian inference are left in \hyperref[appB]{Appendix \textbf{\ref{appB}}}.


This chapter is mostly based on \citet[sec. 9.1]{coles_introduction_2001},  \citet[chap.11]{beirlant_statistics_2006}, \citet[chap.13]{dey_extreme_2016} and \citet[chap.3]{ag_extremes_2013},  and other relevant articles.

\newpage
\include*{chap4}





\part{Experimental Framework : Extreme Value Analysis of Maximum Temperatures}\label{part:xp}
\thispagestyle{empty}

%In this part, we will focus on the application of the methods seen during the theoretical part. 

\chapter{Introduction to the Analysis}\label{chap:introana}
\vspace{-1cm}
\minitoc \thispagestyle{empty}
 \vspace{1cm}
 
Since we have theoretically defined useful concepts in EVT, we will now introduce the practical analysis of this thesis that consist of analyzing daily maximum temperatures in Uccle from 1901 to 2016.  
We have already showed the distribution of this data in Figure \ref{fig:pot_plot} to introduce the POT approach. This chapter will present an introductory analysis of the \emph{annual} maxima of these data, which will provide a convenient GEV modeling. We will then use several techniques to analyze the data before going further into the EV models in the following chapters. 

After a brief presentation of the repository which contains the R package created for this thesis and the structure for the scripts that contains the code that created all the analysis, this chapter briefly present the shiny applications created to enhance visualizations. \hyperref[sec:presuccle]{Section \textbf{\ref{sec:presuccle}}} will present data and its source. \hyperref[sec:firstana]{Section \textbf{\ref{sec:firstana}}} will first describe data and compare models to represent the data before going further on the trend analysis with splines derivatives in a Generalized Additive Model to assess the significance of the trend with correction for simultaneous tests and provide the first aspects in the issue of Climate Warming without using extreme models. 


This chapter will not explicitly use techniques presented in the previous chapters. It will be mostly based on \citet{ruppert_semiparametric_2003} for the model presented in \hyperref[sec:splines]{Section \textbf{\ref{sec:splines}}}. 
  

\newpage
\include*{chap5}



\chapter{Analysis in Block Maxima}\label{sec:anagev}
\minitoc \thispagestyle{empty}
 \vspace{1cm}
 
 This chapter introduces the core subject of this thesis, the stationary and nonstationary GEV analysis for the annual maximum temperatures in Uccle. Concepts borrowed from \hyperref[sec::1]{Chapter \textbf{\ref{sec::1}}} and \hyperref[sec::3]{Chapter \textbf{\ref{sec::3}}} will be used. POT analysis of \hyperref[sec::2]{Chapter \textbf{\ref{sec::2}}} will be mentioned but all results are kept in the code. 

In \hyperref[sec:xpstatio]{Section \textbf{\ref{sec:xpstatio}}}, we will present GEV inferences assuming stationarity which relies on \\ \texttt{1intro\_stationary.R} code from the \textbf{/Scripts-R/} folder of the \href{https://github.com/proto4426/PissoortThesis/}{repository}.
\hyperref[sec:xpnp]{Section \textbf{\ref{sec:xpnp}}} will introduce the nonstationary analysis with parametric models and relies on \texttt{2Nonstationary.R} code, while \hyperref[sec:nnxp]{Section \textbf{\ref{sec:nnxp}}} allows for more complex models from deep architectures and relies on \texttt{2NeuralsNets.R} code. 

Although some Bayesian concepts will be used in this section such as use of \emph{prior distributions} for the EVI to limit its domain when estimating it with a likelihood-based method, or to regularize weights of Neural Networks in \hyperref[sec:nnxp]{Section \textbf{\ref{sec:nnxp}}}, we will still call all these methods as "frequentists".
A strict Bayesian analysis will be made in \hyperref[sec:anabayes]{next Chapter \textbf{\ref{sec:anabayes}}} and comparisons will be provided.

\newpage
\include*{chap6}


%%%%%%%%%%%%%%%%%%%%%%%%
\iffalse
\chapter{Stationary and Nonstationary GEV Analysis}\label{sec:ananonsta}
\minitoc \thispagestyle{empty}
 \vspace{1cm}
\include*{chap8}
\fi
%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Bayesian Analysis in Block Maxima}\label{sec:anabayes}
\minitoc \thispagestyle{empty}
 \vspace{1cm}
 
Bayesian analysis is more and more used everywhere. For example in this text,  \hyperref[chap:introana]{Chapter \textbf{\ref{chap:introana}}} used a simulation-based Bayesian approach to compare coverage properties of pointwise and simultaneous confidence intervals, while \hyperref[sec:nnxp]{Section \textbf{\ref{sec:nnxp}}} used priors to constraint the domain of the shape parameter or to penalize weights in a neural network's architecture. %This chapter aims at presenting an other 

After briefly presenting the available methods in \hyperref[sec:meth]{Section \textbf{\ref{sec:meth}}} and discussing our choice, \hyperref[sec:baystatio]{Section \textbf{\ref{sec:baystatio}}} will briefly present the GEV stationary model in order to compare the three leading algorithms by Bayesian's practitioners for sampling with Markov Chain Monte Carlo. \hyperref[sec:baycomp]{Section \textbf{\ref{sec:baycomp}}} will focus on the comparison of nonstationary models with predictive accuracy criteria in order to select the model that will be carefully analyzed in 
\hyperref[sec:bay_nonsta]{Section \textbf{\ref{sec:bay_nonsta}}}. Great importance of convergence issues will be given, with great visual demonstrations and comparisons with the results obtained in the last chapter. 
\hyperref[sec:rem]{Section \textbf{\ref{sec:rem}}} will conclude the chapter by discussing other possibles techniques and will also provide a great summary of the credible (or confidence) intervals obtained for the parameters during this whole text.

This analysis relies on all the scripts with filenames starting with "\texttt{Bayes\_}" in the \textbf{/Scripts-R/} folder of the \href{https://github.com/proto4426/PissoortThesis/}{repository}. Especially \texttt{Bayes\_own\_gev.R} is useful to retrieve the outputs of the chapter.  All the functions created that are used and made available through the package are in /R/\texttt{BayesFunc.R}. Moreover,
the \texttt{/vignettes/Summary\_Bayesian.html} file in the \href{https://github.com/proto4426/PissoortThesis/}{repository} presents the analysis in details.

\newpage
\include*{chap7}




\addcontentsline{toc}{chapter}{Conclusion}
\chapter*{Conclusion}
\thispagestyle{empty}

\iffalse
Dans l'introduction et dans la conclusion, ce serait bien de mieux préciser, de façon structurée :
- la question ou les questions de recherche
- les données
- la méthodologie (bien motiver tes choix de méthodes)
- les réponses trouvées aux questions énoncées initialement
\fi

This thesis aimed at statistically assessing the presence of a nonstationary model for a sequence of annual maximum temperatures in Uccle from $1901$ to $2016$ by hand of the Extreme Value Theory. The data were gratefully provided by an official institution in order to evaluate the effects of the climate warming.
To this end, we have divided the text in two parts that makes a clear separation between the literature review (\hyperref[part1]{Part \textbf{\ref{part1}}}) and the application of the methods (\hyperref[part:xp]{Part \textbf{\ref{part:xp}}}).

\hyperref[part1]{Part \textbf{\ref{part1}}} started by presenting the approach of block maxima in \hyperref[sec::1]{Chapter \textbf{\ref{sec::1}}} that models the extremes that occurs inside a block. It introduced the GEV distribution and its parameters that form at the basis of the nonstationary models.
The second approach of modeling extremes discussed in \hyperref[sec::2]{Chapter \textbf{\ref{sec::2}}} aims a modeling the extremes that exceed a certain threshold.
Since we have decided to work only with annual maxima due to space constraints, we have put more emphasis on the first approach. In order to evaluate the form of the nonstationarity in the sequence,
\hyperref[sec::3]{Chapter \textbf{\ref{sec::3}}} delivered tools that permitted to go beyond the restrictive independence assumption of the first two chapters. This provided us tools to consider different parametric models for the GEV parameters that will form the basis of the nonstationary analysis, but also a flexible approach using Neural Networks to surpass  the restrictive parametric assumption.
\hyperref[sec::bayesian]{Chapter \textbf{\ref{sec::bayesian}}} presented the Bayesian analysis applied to the world of extremes which provided us inferential methods that better account for both  estimation and prediction uncertainty. 

In \hyperref[part:xp]{Part \textbf{\ref{part:xp}}},  \hyperref[chap:introana]{Chapter \textbf{\ref{chap:introana}}} introduced the analysis with some methods not from EVT to get first insights on the analysis of the trend. Although the trend were found significant from a simple linear regression, simultaneous intervals based on splines derivatives of a Generalized dditive Model in highlighted that the trend is not significant over time, whilst pointwise intervals emphasized the accelerating trend of the annual maxima in the last $40$ years. This accelerating behavior of the annual maxima in the end of the sequence was confirmed in the end of \hyperref[sec:anagev]{Chapter \textbf{\ref{sec:anagev}}} by a bootstrap aggregated Neural Network which used a deep nonlinear model taking care of overfitting. But before that, we discovered that the best and most parsimonious parametric GEV model had only a linear trend on the location parameter. This was also the model selected by the flexible modeling with Neural Networks according to information criteria that also prevented overfitting, among a large number of models. \hyperref[sec:anabayes]{Chapter \textbf{\ref{sec:anabayes}}} finally confirmed  with predictive accuracy criteria that the nonstationary GEV model with a simple linear model on the location parameter was the best among some carefully chosen parametric models. Hence,
% \textbf{we can conclude with the support of three intrinsically different modeling techniques relying on the GEV distribution that there is a linear trend on the location of the annual maxima in Uccle.} %However, caution should always be put when extrapolating from
\vspace{.2cm}
\begin{tcolorbox}
	we can conclude with the support of three intrinsically different modeling techniques relying on the GEV distribution that there is a linear trend on the location of the annual maxima in Uccle.
\end{tcolorbox}
Nevertheless, a climatologist of the IRM made the important remark that an artificial warming is observed on cities' stations which were significantly less urbanized $100$ years ago, such as Uccle for example. Together with the limitations we specified during the whole \hyperref[part:xp]{Part \textbf{\ref{part:xp}}}, conclusions and interpretations that we can draw from this statistical fact should be tempered by great caution.
\newline

Time and space constraints now lead us to enumerate some methods and attempts for improvements that have not been studied in this thesis : 

\begin{itemize} 
\item From the pioneering thesis of \citet{Neal_1996_bay}, \emph{Bayesian Neural Networks} are now widely used for their deep flexibility. In our case and to make it simple, it would roughly means combining the flexibility of the GEV-CDN framework (in the sense of being capable of modelling any relationships)  of \hyperref[sec:nnxp]{Sections \textbf{\ref{sec:nnxp}}} and \hyperref[sec:gevcdn]{ \textbf{\ref{sec:gevcdn}}} with the flexibility of the  Bayesian analysis (in the sense of being able to tune a vast amount of information) of \hyperref[sec::bayesian]{ Chapters \textbf{\ref{sec::bayesian}}} and \textbf{\ref{sec:anabayes}}. Hence, it would be perfect to surpass the restrictive assumption of parametric models that we have considered in the Bayesian chapters.

%Even if we were not able to execute some dangerous methods such as the Hamiltonian Monte Carlo or the computation of the Bayes factor for example, this thesis allowed to learn by doing 

\item During this whole thesis we considered time as the sole covariate to explain the change in the extreme temperatures. Other covariates could have been included to improve the nonstationary analysis. To name a few : \emph{Southern Oscillation Index} (a proxy for El Niño), the $\text{CO}_2$ level, etc.
However, most of these are (highly) time-dependent, and linking to a climatological covariate makes
extrapolation into the future more difficult as one would need to extrapolate the covariate as well. 

\item Since the IRM is able to provide temperature measurements in real-time, it would be feasible to automate all the methods and the analysis by using similar tools (e.g. in the R package or in a Shiny application) in order to automatically take into account each new observations, providing live updates of the statistical models.

\item \citet{Ribes2017} noticed that winter is becoming especially warmer in the context of climate warming.
Computationally speaking, it would require only a few changes in order to provide the same analysis as done with maxima. Here again, an automated method would be very easy but really worth implementing.
\end{itemize}

Finally, we must notice this thesis analyzed the increasing behavior of extreme temperatures, but it did neither study the causality of this change nor made an extensive analysis of the anthropogenic nature of the global warming, which is often the big issue.

\thispagestyle{empty}

%Finish (Bayesian) documentation in the package.


%\clearpage
\addcontentsline{toc}{part}{Appendix}
\part*{Appendix}
\appendix

\include*{appendix}




\bibliographystyle{ieeetr}
\setlength{\parindent}{5em}
\setlength{\parskip}{2em}
\renewcommand{\baselinestretch}{4.0}

\bibliography{zotero1}

\end{document}